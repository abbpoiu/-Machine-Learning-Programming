{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1o0PjzDIuE0SjmcxAoOuxe0T1dv2eyWWf","authorship_tag":"ABX9TyN5iewgNl/QgPIERLr+GVfK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":370},"id":"LpjoqWFUW12o","executionInfo":{"status":"error","timestamp":1757386494098,"user_tz":-540,"elapsed":73,"user":{"displayName":"준한","userId":"10675742586200363268"}},"outputId":"f71bd234-2696-4485-8e8c-587ebe39face"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3780497194.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m X_tr, X_te, y_tr, y_te = train_test_split(\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2870\u001b[0m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2872\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_common_namespace_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \"\"\"\n\u001b[1;32m   1908\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1909\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1910\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2318\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2319\u001b[0m                 \u001b[0;34m\"The least populated class in y has only 1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2320\u001b[0m                 \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","\n","\n","# -----------------------------\n","# 1) 데이터 준비\n","# -----------------------------\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/boston.csv\").dropna()\n","\n","\n","\n","X = df.drop(columns=[\"PRICE\"])\n","y = df[\"PRICE\"].astype(float)\n","\n","\n","num_cols = [c for c in X.columns if pd.api.types.is_numeric_dtype(X[c])]\n","cat_cols = [c for c in X.columns if c not in num_cols]\n","\n","preprocess = ColumnTransformer(\n","    transformers=[\n","        (\"num\", StandardScaler(), num_cols),\n","        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n","    ],\n","    remainder=\"drop\"\n",")\n","\n","X_tr, X_te, y_tr, y_te = train_test_split(\n","\n","    X, y, test_size=0.2, stratify=y, random_state=42\n","\n",")\n","\n","# -----------------------------\n","# 2) 모델 구성\n","# -----------------------------\n","dt = DecisionTreeRegressor(random_state=42)\n","rf = RandomForestRegressor(n_estimators=200, random_state=42)\n","\n","\n","# -----------------------------\n","# 3) 모델 학습\n","# -----------------------------\n","def evaluate(pipe, X_te, y_te):\n","    pred = pipe.predict(X_te)\n","    mae = mean_absolute_error(y_te, pred)\n","    rmse = mean_squared_error(y_te, pred, squared=False)\n","    r2 = r2_score(y_te, pred)\n","    return mae, rmse, r2\n","\n","# -----------------------------\n","# 4) 모델 평가\n","# -----------------------------\n","results = []\n","for name, pipe in models.items():\n","    pipe.fit(X_tr, y_tr)\n","    mae, rmse, r2 = evaluate(pipe, X_te, y_te)\n","    results.append((name, mae, rmse, r2))\n","\n","print(\"=== Test Metrics (lower MAE/RMSE better, higher R2 better) ===\")\n","for name, mae, rmse, r2 in results:\n","    print(f\"{name:22s} | MAE: {mae:.3f} | RMSE: {rmse:.3f} | R2: {r2:.3f}\")\n","\n"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_diabetes\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","\n","# -----------------------------\n","# 1) 데이터 준비 (회귀용)\n","# -----------------------------\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/boston.csv\").dropna()\n","\n","\n","X = df.drop(columns=[\"PRICE\"])\n","y = df[\"PRICE\"]\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n","\n",")\n","\n","# -----------------------------\n","# 2) 모델 구성 (회귀 모델)\n","# -----------------------------\n","\n","dt = DecisionTreeRegressor(random_state=42)\n","rf = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n","\n","\n","# 선형회귀는 스케일링과 함께 파이프라인 구성 권장\n","\n","lr = make_pipeline(StandardScaler(with_mean=True, with_std=True), LinearRegression())\n","\n","\n","# -----------------------------\n","# 3) 모델 학습\n","# -----------------------------\n","\n","dt.fit(X_train, y_train)\n","rf.fit(X_train, y_train)\n","lr.fit(X_train, y_train)\n","\n","\n","# -----------------------------\n","# 4) 모델 평가 함수\n","# -----------------------------\n","\n","def eval_reg(y_true, y_pred):\n","    mae  = mean_absolute_error(y_true, y_pred)\n","    mse  = mean_squared_error(y_true, y_pred)  # squared 인자 제거\n","    rmse = np.sqrt(mse)                        # 직접 제곱근\n","    r2   = r2_score(y_true, y_pred)\n","    return mae, rmse, r2\n","\n","\n","\n","dt_mae, dt_rmse, dt_r2 = eval_reg(y_test, dt.predict(X_test))\n","rf_mae, rf_rmse, rf_r2 = eval_reg(y_test, rf.predict(X_test))\n","lr_mae, lr_rmse, lr_r2 = eval_reg(y_test, lr.predict(X_test))\n","\n","\n","print(\"=== Test Metrics (Regression) ===\")\n","\n","print(\"[Decision Tree]\")\n","print(f\"MAE: {dt_mae:.3f} | RMSE: {dt_rmse:.3f} | R^2: {dt_r2:.3f}\")\n","\n","print(\"[Random Forest]\")\n","print(f\"MAE: {rf_mae:.3f} | RMSE: {rf_rmse:.3f} | R^2: {rf_r2:.3f}\")\n","\n","print(\"[Linear Regression]\")\n","print(f\"MAE: {lr_mae:.3f} | RMSE: {lr_rmse:.3f} | R^2: {lr_r2:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTLzRv8eZSbI","executionInfo":{"status":"ok","timestamp":1757387036723,"user_tz":-540,"elapsed":55851,"user":{"displayName":"준한","userId":"10675742586200363268"}},"outputId":"129450a2-b587-4200-c9af-ce18701fcedf"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Test Metrics (Regression) ===\n","[Decision Tree]\n","MAE: 0.444 | RMSE: 0.694 | R^2: 0.632\n","[Random Forest]\n","MAE: 0.314 | RMSE: 0.489 | R^2: 0.818\n","[Linear Regression]\n","MAE: 0.532 | RMSE: 0.745 | R^2: 0.577\n"]}]}]}