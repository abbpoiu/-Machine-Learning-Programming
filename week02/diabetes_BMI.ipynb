{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1octt6y4Uk3Oya40K9d_8GdrRhNUQAPN2","authorship_tag":"ABX9TyPBY5W5T3kKzh690N/LokFb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"2JL79f-X0B1J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757763888696,"user_tz":-540,"elapsed":3427,"user":{"displayName":"준한","userId":"10675742586200363268"}},"outputId":"648a3fff-2815-4ea2-87cb-821a49fd3fe0"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Regression Test Metrics (BMI) ===\n","Decision Tree  | MAE: 7.2513 | RMSE: 10.2043 | R2: -0.4648\n","Random Forest  | MAE: 5.1743 | RMSE: 6.8293 | R2: 0.3439\n","Linear Reg.    | MAE: 5.2110 | RMSE: 7.2278 | R2: 0.2651\n"]}],"source":["# =============================\n","# 0) 기본 라이브러리\n","# =============================\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import numpy as np\n","import re\n","\n","# -----------------------------\n","# 1) 데이터 준비\n","# -----------------------------\n","# 내가 실질적으로 준비하는 부분. (전처리)\n","# 데이터 준비와 label/feature 분리, 결측치 제거, 학습/테스트 데이터 분리.\n","# 이후 구성, 학습, 평가 부분은 사이킷런이 해준것.\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/diabetes_1.csv\")\n","\n","# 1) feature / label 분리\n","X = df.drop(columns=[\"BMI\"])\n","y = df[\"BMI\"]\n","\n","# 숫자형만 사용(문자형이 섞였다면 간단히 제외)\n","X = X.select_dtypes(include=[np.number])\n","\n","# 2) 결측치 제거(디폴트 스타일 유지: dropna)\n","#    X와 y를 합쳐 결측이 있는 행을 통째로 제거\n","data = pd.concat([X, y], axis=1).dropna()\n","X = data.drop(columns=[\"BMI\"])\n","y = data[\"BMI\"]\n","\n","# 3) 학습용 / 테스트용 분리 (랜덤 셔플 포함)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# -----------------------------\n","# 2) 모델 구성\n","# -----------------------------\n","dt = DecisionTreeRegressor(random_state=42)\n","rf = RandomForestRegressor(n_estimators=300, random_state=42)\n","lr = LinearRegression()\n","# 구성된 모델 가져옴. 분류와 다른점은 회귀이기 때문에 regressor 함수를 불러온게 다름.\n","\n","# -----------------------------\n","# 3) 모델 학습\n","# -----------------------------\n","dt.fit(X_train, y_train)\n","rf.fit(X_train, y_train)\n","lr.fit(X_train, y_train)\n","\n","# -----------------------------\n","# 4) 모델 평가\n","# -----------------------------\n","# 회귀 평가지표:\n","# - MAE: 평균 절대 오차(평균적으로 얼마나 틀렸는가)\n","# - RMSE: 제곱근 평균 제곱 오차(큰 오차에 더 큰 패널티)\n","# - R2: 결정계수(평균 예측 대비 얼마나 개선되었는가)\n","\n","def evaluate(model, X_test, y_test):\n","    pred = model.predict(X_test)\n","    mae = mean_absolute_error(y_test, pred)\n","    mse = mean_squared_error(y_test, pred)\n","    rmse = np.sqrt(mse)\n","    r2 = r2_score(y_test, pred)\n","    return mae, rmse, r2\n","\n","dt_mae, dt_rmse, dt_r2 = evaluate(dt, X_test, y_test)\n","rf_mae, rf_rmse, rf_r2 = evaluate(rf, X_test, y_test)\n","lr_mae, lr_rmse, lr_r2 = evaluate(lr, X_test, y_test)\n","\n","print(\"=== Regression Test Metrics (BMI) ===\")\n","print(f\"Decision Tree  | MAE: {dt_mae:.4f} | RMSE: {dt_rmse:.4f} | R2: {dt_r2:.4f}\")\n","print(f\"Random Forest  | MAE: {rf_mae:.4f} | RMSE: {rf_rmse:.4f} | R2: {rf_r2:.4f}\")\n","print(f\"Linear Reg.    | MAE: {lr_mae:.4f} | RMSE: {lr_rmse:.4f} | R2: {lr_r2:.4f}\")\n"]}]}